{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Stage-1：Data Access"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df_train = pd.read_csv('./datasetes/driver/train.csv')\n",
    "df_test = pd.read_csv('./datasetes/driver/test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(21694, 59)\n",
      "(573518, 59)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.037826188541597645"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(df_train[df_train.target==1].shape)\n",
    "print(df_train[df_train.target==0].shape)\n",
    "df_train[df_train.target==1].shape[0]/df_train[df_train.target==0].shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "target_train = df_train['target'].values\n",
    "id_train = df_train['id'].values\n",
    "id_test = df_test['id'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df_train = df_train.drop(['target','id'],axis=1)\n",
    "df_test = df_test.drop(['id'], axis = 1)\n",
    "# combine = pd.concat([df_train,df_test],axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The train shape is: (595212, 57)\n",
      "The test shape is: (892816, 57)\n"
     ]
    }
   ],
   "source": [
    "print (\"The train shape is:\",df_train.shape)\n",
    "print ('The test shape is:',df_test.shape)\n",
    "# print ('The combine shape is:',combine.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Stage-2：Model application"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn import tree\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.model_selection import StratifiedShuffleSplit\n",
    "import ForestUtils\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def gini(actual, pred, cmpcol = 0, sortcol = 1):\n",
    "    assert( len(actual) == len(pred) )\n",
    "    all = np.asarray(np.c_[ actual, pred, np.arange(len(actual)) ], dtype=np.float)\n",
    "    all = all[ np.lexsort((all[:,2], -1*all[:,1])) ]\n",
    "    totalLosses = all[:,0].sum()\n",
    "    giniSum = all[:,0].cumsum().sum() / totalLosses\n",
    "    \n",
    "    giniSum -= (len(actual) + 1) / 2.\n",
    "    return giniSum / len(actual)\n",
    "\n",
    "def gini_normalized(a, p):\n",
    "    return gini(a, p) / gini(a, a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def TrainModelLayer(X, y):\n",
    "    sss = StratifiedShuffleSplit(n_splits=1, test_size=0.15, random_state=9487)\n",
    "    split_obj = tuple(sss.split(X, y))\n",
    "    train_index, test_index = split_obj[0]\n",
    "    X_train, X_valid = X[train_index], X[test_index]\n",
    "    y_train, y_valid = y[train_index], y[test_index]\n",
    "    print(\"X_train.shape, y_train.shape:\"+str(X_train.shape)+str(y_train.shape))\n",
    "    print(\"X_valid.shape, y_valid.shape:\"+str(X_valid.shape)+str(y_valid.shape))\n",
    "    \n",
    "    clf = DecisionTreeClassifier(max_depth=10, random_state=1024, min_samples_leaf=100, #max_leaf_nodes=100,\n",
    "#                                  n_estimators=2, n_jobs=8, oob_score=True, verbose=1, boostrap=False,\n",
    "                                 criterion='gini')\n",
    "#     print(\"train start:\"+str(clf))\n",
    "#     DecisionTreeClassifier(criterion='gini', splitter='best', max_depth=None, min_samples_split=2, min_samples_leaf=1, \n",
    "#                            min_weight_fraction_leaf=0.0, max_features=None, random_state=None, max_leaf_nodes=None, \n",
    "#                            min_impurity_decrease=0.0, min_impurity_split=None, class_weight=None, presort=False)\n",
    "    clf = clf.fit(X_train, y_train)\n",
    "#     print(\"train success\")\n",
    "\n",
    "    p_train = clf.predict_proba(X)\n",
    "    p_train = [item[1] for item in p_train]\n",
    "    p_train = np.array(p_train)\n",
    "    print(\"data nor-gini:\"+str(gini_normalized(y, p_train)))\n",
    "    \n",
    "    p_train = clf.predict_proba(X_train)\n",
    "    p_train = [item[1] for item in p_train]\n",
    "    p_train = np.array(p_train)\n",
    "    print(\"train nor-gini:\"+str(gini_normalized(y_train, p_train)))\n",
    "    \n",
    "    p_valid = clf.predict_proba(X_valid)\n",
    "    p_valid = [item[1] for item in p_valid]\n",
    "    p_valid = np.array(p_valid)\n",
    "    print(\"vaild nor-gini:\"+str(gini_normalized(y_valid, p_valid)))\n",
    "\n",
    "    # Predict on our test data\n",
    "#     p_test = clf.predict_proba(test)\n",
    "#     p_test = [item[1] for item in p_test]\n",
    "#     p_test = np.array(p_test)\n",
    "\n",
    "    \n",
    "    return clf, X_train, X_valid, y_train, y_valid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def LayerPerformance(clf, X_train):\n",
    "    impurity = clf.tree_.impurity\n",
    "    threshold = clf.tree_.threshold\n",
    "    impurity_index = np.argsort(impurity, axis=0)  \n",
    "    \n",
    "    for id in impurity_index:\n",
    "        if threshold[id] != -2: continue\n",
    "        ForestUtils.print_node_info(clf, id)\n",
    "        for item in X_train:\n",
    "            sample_list = [item]\n",
    "            leave_id = clf.apply(sample_list)[0]\n",
    "            if leave_id == id:\n",
    "                ForestUtils.print_decision_path_ofsample(clf, item)\n",
    "                break\n",
    "        print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def DataSplit(estimator, X_train, y_train):\n",
    "    data_id_list = np.array(list(range(len(X_train))))\n",
    "    # S0 对于一个决策树返回所有叶子节点的gini排序计算平均\n",
    "    impurity = estimator.tree_.impurity\n",
    "    # impurity_index = np.argsort(impurity, axis=0)  \n",
    "    mean_imp = np.mean(impurity, axis=0)\n",
    "    print(\"mean of all impurity:\" + str(mean_imp))\n",
    "\n",
    "    # S1 通过gini获取相关节点id\n",
    "    # pass_node_num = impurity[impurity[impurity_index] < mean_imp].shape[0]\n",
    "    # pass_node_id_lt = impurity_index[:pass_node_num]\n",
    "    pass_node_id_lt = np.where(impurity < mean_imp)[0]\n",
    "    print(\"pass node id shape:\" + str(pass_node_id_lt.shape))\n",
    "\n",
    "    # S2 通过node id获取相关数据\n",
    "    node_id_lt = estimator.apply(X_train)\n",
    "    # pass_data_id_lt = []\n",
    "    # for i, node_id in enumerate(node_id_lt):\n",
    "    #     if node_id in pass_node_id_lt:\n",
    "    #         pass_data_id_lt.append(i)\n",
    "    # len(pass_data_id_lt)\n",
    "    node_id_mask = np.isin(node_id_lt, pass_node_id_lt)\n",
    "#     print(node_id_mask, node_id_mask.shape)\n",
    "#     pass_data_id_lt = data_id_list[node_id_mask]\n",
    "#     print(pass_data_id_lt, pass_data_id_lt.shape)\n",
    "#     print(\"pass data id shape:\" + str(pass_data_id_lt.shape))\n",
    "\n",
    "    # S3 通过pass data id分割数据\n",
    "#     pass_data_mask = np.isin(data_id_list, pass_data_id_lt)\n",
    "    pass_data_mask = node_id_mask\n",
    "    X_train_pass = X_train[pass_data_mask]\n",
    "    y_train_pass = y_train[pass_data_mask]\n",
    "    X_train_np = X_train[~pass_data_mask]\n",
    "    y_train_np = y_train[~pass_data_mask]\n",
    "#     print(\"pass data shape:\" + str(X_train_pass.shape), y_train_pass[y_train_pass==1].shape)\n",
    "#     print(\"not pass data shape:\" + str(X_train_np.shape), X_train_np[X_train_np==1].shape)\n",
    "#     print(\"all data shape:\" + str(X_train_pass.shape[0]+X_train_np.shape[0]))\n",
    "    \n",
    "    return X_train_pass, y_train_pass, X_train_np, y_train_np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 324,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def TestDataSplit(estimator, X_test):\n",
    "    # S0 对于一个决策树返回所有叶子节点的gini排序计算平均\n",
    "    impurity = estimator.tree_.impurity\n",
    "    mean_imp = np.mean(impurity, axis=0)\n",
    "    print(\"mean of all impurity:\" + str(mean_imp))\n",
    "\n",
    "    # S1 通过gini获取相关节点id\n",
    "    pass_node_id_lt = np.where(impurity < mean_imp)[0]\n",
    "    print(\"pass node id shape:\" + str(pass_node_id_lt.shape))\n",
    "\n",
    "    # S2 通过node id获取相关数据\n",
    "    node_id_lt = estimator.apply(X_test)\n",
    "    node_id_mask = np.isin(node_id_lt, pass_node_id_lt)\n",
    "    \n",
    "    # S3 输出预测结果\n",
    "    p_test = estimator.predict_proba(X_test)\n",
    "    p_test = [item[1] for item in p_test]\n",
    "    p_test = np.array(p_test)\n",
    "    \n",
    "    return node_id_mask, p_test "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train = np.array(df_train)\n",
    "test = np.array(df_test)\n",
    "X = train\n",
    "y = target_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train.shape, y_train.shape:(505930, 57)(505930,)\n",
      "X_valid.shape, y_valid.shape:(89282, 57)(89282,)\n",
      "data nor-gini:0.298615876168\n",
      "train nor-gini:0.316690280626\n",
      "vaild nor-gini:0.195871634709\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "DecisionTreeClassifier(class_weight=None, criterion='gini', max_depth=10,\n",
       "            max_features=None, max_leaf_nodes=None,\n",
       "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "            min_samples_leaf=100, min_samples_split=2,\n",
       "            min_weight_fraction_leaf=0.0, presort=False, random_state=1024,\n",
       "            splitter='best')"
      ]
     },
     "execution_count": 131,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# clf, X_train, X_valid, y_train, y_valid = TrainModelLayer(X, y)\n",
    "# clf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# LayerPerformance(clf, X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mean of all impurity:0.116536678108\n",
      "pass node id shape:(466,)\n",
      "pass data id shape:(537350,)\n",
      "[ 92  98 114 135 195  94 172 195 648 192] (537350,)\n",
      "595212\n",
      "(595212,) (213,)\n",
      "pass data shape:(213, 57) (9,)\n",
      "not pass data shape:(594999, 57) (6788379,)\n",
      "all data shape:595212\n"
     ]
    }
   ],
   "source": [
    "# X_train_pass, y_train_pass, X_train_np, y_train_np = DataSplit(clf, X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# len(train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# t_y_train = np.array([[item] for item in y_train])\n",
    "# mask_y_train_1 = np.where(np.any(t_y_train==1, axis=1))[0]\n",
    "# mask_y_train_0 = np.where(np.any(t_y_train==0, axis=1))[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 284,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# len(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 325,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "layer: 1\n",
      "X_train.shape, y_train.shape:(36879, 57)(36879,)\n",
      "X_valid.shape, y_valid.shape:(6509, 57)(6509,)\n",
      "data nor-gini:0.311249192135\n",
      "train nor-gini:0.318810690676\n",
      "vaild nor-gini:0.197394580887\n",
      "mean of all impurity:0.462394526573\n",
      "pass node id shape:(119,)\n",
      "not pass data shape:(29596, 57) (14703,)\n",
      "pass data shape:(13792, 57) (6991,)\n",
      "next train data shape:(581420, 57) (14703,)\n",
      "all data shape:595212\n",
      "mean of all impurity:0.462394526573\n",
      "pass node id shape:(119,)\n",
      "\n",
      "layer: 2\n",
      "X_train.shape, y_train.shape:(24995, 57)(24995,)\n",
      "X_valid.shape, y_valid.shape:(4411, 57)(4411,)\n",
      "data nor-gini:0.241508564816\n",
      "train nor-gini:0.248922343379\n",
      "vaild nor-gini:0.0727091440989\n",
      "mean of all impurity:0.478016777264\n",
      "pass node id shape:(87,)\n",
      "not pass data shape:(18850, 57) (9374,)\n",
      "pass data shape:(10556, 57) (5329,)\n",
      "next train data shape:(570864, 57) (9374,)\n",
      "all data shape:581420\n",
      "mean of all impurity:0.478016777264\n",
      "pass node id shape:(87,)\n",
      "\n",
      "layer: 3\n",
      "X_train.shape, y_train.shape:(15935, 57)(15935,)\n",
      "X_valid.shape, y_valid.shape:(2813, 57)(2813,)\n",
      "data nor-gini:0.232315172149\n",
      "train nor-gini:0.220554207542\n",
      "vaild nor-gini:0.0415277807265\n",
      "mean of all impurity:0.482107817887\n",
      "pass node id shape:(50,)\n",
      "not pass data shape:(12367, 57) (6184,)\n",
      "pass data shape:(6381, 57) (3190,)\n",
      "next train data shape:(564483, 57) (6184,)\n",
      "all data shape:570864\n",
      "mean of all impurity:0.482107817887\n",
      "pass node id shape:(50,)\n",
      "\n",
      "layer: 4\n",
      "X_train.shape, y_train.shape:(10512, 57)(10512,)\n",
      "X_valid.shape, y_valid.shape:(1856, 57)(1856,)\n",
      "data nor-gini:0.223270857983\n",
      "train nor-gini:0.230094069487\n",
      "vaild nor-gini:-0.000784965814507\n",
      "mean of all impurity:0.482131878478\n",
      "pass node id shape:(41,)\n",
      "not pass data shape:(7180, 57) (3644,)\n",
      "pass data shape:(5188, 57) (2540,)\n",
      "next train data shape:(559295, 57) (3644,)\n",
      "all data shape:564483\n",
      "mean of all impurity:0.482131878478\n",
      "pass node id shape:(41,)\n",
      "\n",
      "layer: 5\n",
      "X_train.shape, y_train.shape:(6194, 57)(6194,)\n",
      "X_valid.shape, y_valid.shape:(1094, 57)(1094,)\n",
      "data nor-gini:0.241614412697\n",
      "train nor-gini:0.258461191677\n",
      "vaild nor-gini:0.0134922412093\n",
      "mean of all impurity:0.483629281231\n",
      "pass node id shape:(29,)\n",
      "not pass data shape:(3941, 57) (1989,)\n",
      "pass data shape:(3347, 57) (1655,)\n",
      "next train data shape:(555948, 57) (1989,)\n",
      "all data shape:559295\n",
      "mean of all impurity:0.483629281231\n",
      "pass node id shape:(29,)\n",
      "\n",
      "layer: 6\n",
      "X_train.shape, y_train.shape:(3381, 57)(3381,)\n",
      "X_valid.shape, y_valid.shape:(597, 57)(597,)\n",
      "data nor-gini:0.236805446547\n",
      "train nor-gini:0.23152785894\n",
      "vaild nor-gini:0.0195506273709\n",
      "mean of all impurity:0.484645074821\n",
      "pass node id shape:(14,)\n",
      "not pass data shape:(2417, 57) (1259,)\n",
      "pass data shape:(1561, 57) (730,)\n",
      "next train data shape:(554387, 57) (1259,)\n",
      "all data shape:555948\n",
      "mean of all impurity:0.484645074821\n",
      "pass node id shape:(14,)\n",
      "\n",
      "layer: 7\n",
      "X_train.shape, y_train.shape:(2140, 57)(2140,)\n",
      "X_valid.shape, y_valid.shape:(378, 57)(378,)\n",
      "data nor-gini:0.277592753935\n",
      "train nor-gini:0.237201502315\n",
      "vaild nor-gini:0.133842837547\n",
      "mean of all impurity:0.486728504823\n",
      "pass node id shape:(10,)\n",
      "not pass data shape:(1311, 57) (656,)\n",
      "pass data shape:(1207, 57) (603,)\n",
      "next train data shape:(553180, 57) (656,)\n",
      "all data shape:554387\n",
      "mean of all impurity:0.486728504823\n",
      "pass node id shape:(10,)\n",
      "\n",
      "layer: 8\n",
      "X_train.shape, y_train.shape:(1115, 57)(1115,)\n",
      "X_valid.shape, y_valid.shape:(197, 57)(197,)\n",
      "data nor-gini:0.305412514872\n",
      "train nor-gini:0.198619074278\n",
      "vaild nor-gini:0.0478251906823\n",
      "mean of all impurity:0.485949578912\n",
      "pass node id shape:(5,)\n",
      "not pass data shape:(882, 57) (454,)\n",
      "pass data shape:(430, 57) (202,)\n",
      "next train data shape:(552750, 57) (454,)\n",
      "all data shape:553180\n",
      "mean of all impurity:0.485949578912\n",
      "pass node id shape:(5,)\n",
      "\n",
      "layer: 9\n",
      "X_train.shape, y_train.shape:(771, 57)(771,)\n",
      "X_valid.shape, y_valid.shape:(137, 57)(137,)\n",
      "data nor-gini:0.330765200179\n",
      "train nor-gini:0.209407173138\n",
      "vaild nor-gini:-0.167092924126\n",
      "mean of all impurity:0.488760331495\n",
      "pass node id shape:(4,)\n",
      "not pass data shape:(237, 57) (120,)\n",
      "pass data shape:(671, 57) (334,)\n",
      "next train data shape:(552079, 57) (120,)\n",
      "all data shape:552750\n",
      "mean of all impurity:0.488760331495\n",
      "pass node id shape:(4,)\n",
      "\n",
      "layer: 10\n",
      "X_train.shape, y_train.shape:(204, 57)(204,)\n",
      "X_valid.shape, y_valid.shape:(36, 57)(36,)\n",
      "data nor-gini:0.631944444444\n",
      "train nor-gini:0.186274509804\n",
      "vaild nor-gini:-0.265432098765\n",
      "mean of all impurity:0.487169625247\n",
      "pass node id shape:(2,)\n",
      "not pass data shape:(0, 57) (0,)\n",
      "pass data shape:(240, 57) (120,)\n",
      "next train data shape:(551839, 57) (0,)\n",
      "all data shape:552079\n",
      "mean of all impurity:0.487169625247\n",
      "pass node id shape:(2,)\n"
     ]
    }
   ],
   "source": [
    "train = np.array(df_train)\n",
    "test = np.array(df_test)\n",
    "test_y = np.array(([0.0] * len(test)))\n",
    "node_id_mask = np.array([False] * len(test))\n",
    "X = train\n",
    "y = target_train\n",
    "X_test = test\n",
    "\n",
    "# 均衡数据进行layer\n",
    "X_train_np = X\n",
    "y_train_np = y\n",
    "maxlayer = 100\n",
    "layer = 0\n",
    "\n",
    "while 1:\n",
    "    layer += 1\n",
    "    print()\n",
    "    print(\"layer:\", layer)\n",
    "    X = X_train_np\n",
    "    y = y_train_np\n",
    "    \n",
    "    # S1 均衡数据\n",
    "    positive_mask = np.where(y == 1)[0]\n",
    "    negative_mask = np.where(y == 0)[0][:len(positive_mask)]\n",
    "    guest_mask = np.where(y == 0)[0][len(positive_mask):]\n",
    "    guest_data_x = X[guest_mask]\n",
    "    guest_data_y = y[guest_mask]\n",
    "    train_mask = np.hstack((positive_mask, negative_mask))\n",
    "    train_data_x = X[train_mask]\n",
    "    train_data_y = y[train_mask]\n",
    "    \n",
    "    # S2 训练模型并分割数据\n",
    "    clf, X_train, X_valid, y_train, y_valid = TrainModelLayer(train_data_x, train_data_y)\n",
    "    X_train_pass, y_train_pass, X_train_np, y_train_np = DataSplit(clf, train_data_x, train_data_y)\n",
    "    print(\"not pass data shape:\" + str(X_train_np.shape), y_train_np[y_train_np==1].shape)\n",
    "    X_train_np = np.vstack((X_train_np, guest_data_x))\n",
    "    y_train_np = np.hstack((y_train_np, guest_data_y))\n",
    "    print(\"pass data shape:\" + str(X_train_pass.shape), y_train_pass[y_train_pass==1].shape)\n",
    "    print(\"next train data shape:\" + str(X_train_np.shape), y_train_np[y_train_np==1].shape)\n",
    "    print(\"all data shape:\" + str(X_train_pass.shape[0]+X_train_np.shape[0]))\n",
    "    \n",
    "    # S3 输出测试数据结果\n",
    "    X_test_np = X_test[~node_id_mask]\n",
    "    pass_node_id_mask, p_test = TestDataSplit(clf, X_test_np)\n",
    "    node_id_mask_index = np.where(node_id_mask == False)[0]\n",
    "    pass_node_id_mask_index = node_id_mask_index[pass_node_id_mask]\n",
    "    test_y[pass_node_id_mask_index] = p_test[pass_node_id_mask]\n",
    "#     print(test_y[~node_id_mask][pass_node_id_mask])\n",
    "    time.sleep(1)\n",
    "    \n",
    "    if X_train_np.shape[0] < 1000 or layer > maxlayer or y_train_np[y_train_np==1].shape[0] <= 10:\n",
    "#         test_y[~node_id_mask][~pass_node_id_mask] = p_test[~pass_node_id_mask]\n",
    "        pass_node_id_mask_index = node_id_mask_index[~pass_node_id_mask]\n",
    "        test_y[pass_node_id_mask_index] = p_test[~pass_node_id_mask]\n",
    "        break\n",
    "        \n",
    "    node_id_mask[~node_id_mask] = pass_node_id_mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 330,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5159,)"
      ]
     },
     "execution_count": 330,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_y[test_y == 0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 296,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>target</th>\n",
       "      <th>id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.016134</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.025643</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.029184</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.022739</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.044334</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     target  id\n",
       "0  0.016134   0\n",
       "1  0.025643   1\n",
       "2  0.029184   2\n",
       "3  0.022739   3\n",
       "4  0.044334   4"
      ]
     },
     "execution_count": 296,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sub = pd.DataFrame(test_y, columns=['target'])\n",
    "sub['id'] = id_test\n",
    "sub.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 297,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import datetime\n",
    "file_pre = datetime.datetime.now().strftime('%m_%d_%H_%M')\n",
    "sub.to_csv(\"./submission/LayerDTree_\"+file_pre+\".csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 326,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "layer: 1\n",
      "X_train.shape, y_train.shape:(505930, 57)(505930,)\n",
      "X_valid.shape, y_valid.shape:(89282, 57)(89282,)\n",
      "data nor-gini:0.298615876168\n",
      "train nor-gini:0.316690280626\n",
      "vaild nor-gini:0.195871634709\n",
      "mean of all impurity:0.116536678108\n",
      "pass node id shape:(466,)\n",
      "pass data shape:(537350, 57) (16454,)\n",
      "not pass data shape:(57862, 57) (5240,)\n",
      "all data shape:595212\n",
      "mean of all impurity:0.116536678108\n",
      "pass node id shape:(466,)\n",
      "(4260,)\n",
      "(4260,)\n",
      "806137 892816 86679\n",
      "\n",
      "layer: 2\n",
      "X_train.shape, y_train.shape:(49182, 57)(49182,)\n",
      "X_valid.shape, y_valid.shape:(8680, 57)(8680,)\n",
      "data nor-gini:0.250215007452\n",
      "train nor-gini:0.288132309712\n",
      "vaild nor-gini:0.034379188368\n",
      "mean of all impurity:0.181957831189\n",
      "pass node id shape:(157,)\n",
      "pass data shape:(42088, 57) (2957,)\n",
      "not pass data shape:(15774, 57) (2283,)\n",
      "all data shape:57862\n",
      "mean of all impurity:0.181957831189\n",
      "pass node id shape:(157,)\n",
      "(704,)\n",
      "(704,)\n",
      "869416 892816 23400\n",
      "\n",
      "layer: 3\n",
      "X_train.shape, y_train.shape:(13407, 57)(13407,)\n",
      "X_valid.shape, y_valid.shape:(2367, 57)(2367,)\n",
      "data nor-gini:0.277014156483\n",
      "train nor-gini:0.32069839135\n",
      "vaild nor-gini:0.0353426520241\n",
      "mean of all impurity:0.2310875276\n",
      "pass node id shape:(76,)\n",
      "pass data shape:(6700, 57) (607,)\n",
      "not pass data shape:(9074, 57) (1676,)\n",
      "all data shape:15774\n",
      "mean of all impurity:0.2310875276\n",
      "pass node id shape:(76,)\n",
      "(195,)\n",
      "(195,)\n",
      "879322 892816 13494\n",
      "\n",
      "layer: 4\n",
      "X_train.shape, y_train.shape:(7712, 57)(7712,)\n",
      "X_valid.shape, y_valid.shape:(1362, 57)(1362,)\n",
      "data nor-gini:0.27968986006\n",
      "train nor-gini:0.327243617234\n",
      "vaild nor-gini:0.00982410982411\n",
      "mean of all impurity:0.288352014698\n",
      "pass node id shape:(51,)\n",
      "pass data shape:(4380, 57) (535,)\n",
      "not pass data shape:(4694, 57) (1141,)\n",
      "all data shape:9074\n",
      "mean of all impurity:0.288352014698\n",
      "pass node id shape:(51,)\n",
      "(0,)\n",
      "(0,)\n",
      "885847 892816 6969\n",
      "\n",
      "layer: 5\n",
      "X_train.shape, y_train.shape:(3989, 57)(3989,)\n",
      "X_valid.shape, y_valid.shape:(705, 57)(705,)\n",
      "data nor-gini:0.221229643118\n",
      "train nor-gini:0.264526725925\n",
      "vaild nor-gini:-0.0225376174519\n",
      "mean of all impurity:0.346702958915\n",
      "pass node id shape:(28,)\n",
      "pass data shape:(2356, 57) (425,)\n",
      "not pass data shape:(2338, 57) (716,)\n",
      "all data shape:4694\n",
      "mean of all impurity:0.346702958915\n",
      "pass node id shape:(28,)\n",
      "(0,)\n",
      "(0,)\n",
      "889395 892816 3421\n",
      "\n",
      "layer: 6\n",
      "X_train.shape, y_train.shape:(1987, 57)(1987,)\n",
      "X_valid.shape, y_valid.shape:(351, 57)(351,)\n",
      "data nor-gini:0.193741432399\n",
      "train nor-gini:0.243564719817\n",
      "vaild nor-gini:-0.116516010418\n",
      "mean of all impurity:0.41393554389\n",
      "pass node id shape:(12,)\n",
      "pass data shape:(1154, 57) (285,)\n",
      "not pass data shape:(1184, 57) (431,)\n",
      "all data shape:2338\n",
      "mean of all impurity:0.41393554389\n",
      "pass node id shape:(12,)\n",
      "(0,)\n",
      "(0,)\n",
      "891169 892816 1647\n",
      "\n",
      "layer: 7\n",
      "X_train.shape, y_train.shape:(1006, 57)(1006,)\n",
      "X_valid.shape, y_valid.shape:(178, 57)(178,)\n",
      "data nor-gini:0.153129169324\n",
      "train nor-gini:0.214301571038\n",
      "vaild nor-gini:-0.178488767869\n",
      "mean of all impurity:0.454917058268\n",
      "pass node id shape:(5,)\n",
      "pass data shape:(502, 57) (152,)\n",
      "not pass data shape:(682, 57) (279,)\n",
      "all data shape:1184\n",
      "mean of all impurity:0.454917058268\n",
      "pass node id shape:(5,)\n",
      "(0,)\n",
      "(0,)\n",
      "891879 892816 937\n",
      "(0,)\n",
      "892816 892816 0\n"
     ]
    }
   ],
   "source": [
    "train = np.array(df_train)\n",
    "test = np.array(df_test)\n",
    "X = train\n",
    "y = target_train\n",
    "X_test = test\n",
    "test_y = np.array(([0.0] * len(test)))\n",
    "node_id_mask = np.array([False] * len(test))\n",
    "\n",
    "# 不均衡数据进行layer\n",
    "X_train_np = X\n",
    "y_train_np = y\n",
    "maxlayer = 100\n",
    "layer = 0\n",
    "\n",
    "counter = 0\n",
    "while 1:\n",
    "    layer += 1\n",
    "    print()\n",
    "    print(\"layer:\", layer)\n",
    "    X = X_train_np\n",
    "    y = y_train_np\n",
    "    clf, X_train, X_valid, y_train, y_valid = TrainModelLayer(X, y)\n",
    "    X_train_pass, y_train_pass, X_train_np, y_train_np = DataSplit(clf, X, y)\n",
    "    print(\"pass data shape:\" + str(X_train_pass.shape), y_train_pass[y_train_pass==1].shape)\n",
    "    print(\"not pass data shape:\" + str(X_train_np.shape), y_train_np[y_train_np==1].shape)\n",
    "    print(\"all data shape:\" + str(X_train_pass.shape[0]+X_train_np.shape[0]))\n",
    "#     time.sleep(1)\n",
    "    \n",
    "    \n",
    "    # S3 输出测试数据结果\n",
    "    X_test_np = X_test[~node_id_mask]\n",
    "    pass_node_id_mask, p_test = TestDataSplit(clf, X_test_np)\n",
    "    print(p_test[p_test == 0].shape)\n",
    "    node_id_mask_index = np.where(node_id_mask == False)[0]\n",
    "    pass_node_id_mask_index = node_id_mask_index[pass_node_id_mask]\n",
    "    test_y[pass_node_id_mask_index] = p_test[pass_node_id_mask]\n",
    "#     print(test_y[~node_id_mask][pass_node_id_mask])\n",
    "    counter += pass_node_id_mask[pass_node_id_mask == True].shape[0]\n",
    "    print(p_test[pass_node_id_mask][p_test[pass_node_id_mask] == 0].shape)\n",
    "    print(counter, len(test), len(test)-counter)\n",
    "    time.sleep(1)\n",
    "    \n",
    "    if X_train_np.shape[0] < 1000 or layer > maxlayer or y_train_np[y_train_np==1].shape[0] <= 10:\n",
    "#         test_y[~node_id_mask][~pass_node_id_mask] = p_test[~pass_node_id_mask]\n",
    "        pass_node_id_mask_index = node_id_mask_index[~pass_node_id_mask]\n",
    "        test_y[pass_node_id_mask_index] = p_test[~pass_node_id_mask]\n",
    "#         print(test_y[~node_id_mask][~pass_node_id_mask])\n",
    "        counter += pass_node_id_mask[pass_node_id_mask == False].shape[0]\n",
    "        print(p_test[~pass_node_id_mask][p_test[~pass_node_id_mask] == 0].shape)\n",
    "        print(counter, len(test), len(test)-counter)\n",
    "        break\n",
    "        \n",
    "    node_id_mask[~node_id_mask] = pass_node_id_mask\n",
    "#     break\n",
    "#     if X_train_np.shape[0] < 1000 or layer > maxlayer:\n",
    "#         break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
